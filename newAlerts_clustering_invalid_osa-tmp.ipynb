{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invalid OSA for nestle cereals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pos_data(file_path):\n",
    "    df = pd.read_csv(file_path,\n",
    "                parse_dates=['SALES_DT'])\n",
    "    df = df.rename(str.lower, axis='columns')\n",
    "    df.loc[:, 'pos_item_qty'] = df['pos_item_qty'].clip(0, 100000)\n",
    "    df.loc[:, 'price'] = df['price'].clip(0, 100000)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alert_data(file_path):\n",
    "    df = pd.read_csv(file_path,\n",
    "                    parse_dates=['SALES_DT'])\n",
    "    df = df.rename(str.lower, axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_daily_group(df, col_name, percentile_high, percentile_low, minimum_pos):\n",
    "    \"\"\"\n",
    "    Assigns each store/day to one of high-, middle-, slow-selling group\n",
    "    \n",
    "    param df: input dataframe for one item\n",
    "    param string col_name: choose beteween 'pos_item_qty' or 'expected_pos'\n",
    "    param list percentile_list: [high percentile, low percentile]\n",
    "    param int minimum_pos: minimum pos to define a slow selling item\n",
    "    \"\"\"\n",
    "    \n",
    "    top_threshold_qty = df[col_name].quantile(percentile_high)\n",
    "    middle_threshold_qty = df[col_name].quantile(percentile_low)\n",
    "\n",
    "    df['group'] = df.shape[0] * np.nan\n",
    "    if middle_threshold_qty < minimum_pos:\n",
    "        df.loc[:, 'group'] = 'slow'\n",
    "    else:\n",
    "        df.loc[:, 'group'][(df[col_name]>middle_threshold_qty) & (df[col_name]<=top_threshold_qty)] = 'middle'\n",
    "        df.loc[:, 'group'][df[col_name]>top_threshold_qty] = 'top'\n",
    "        df.loc[:, 'group'][df[col_name]<=middle_threshold_qty] = 'slow'\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def select_percentile_comb(df, percentile):\n",
    "    \"\"\"\n",
    "    Calculates how often a item/store aprears in each group. In the list of all appeared days,\n",
    "    calculated x-percentile is the threshold to select stores.\n",
    "    param datafram df: Input dataframe with a column group\n",
    "    param float percentile: percentile to calculate the infimum number of days\n",
    "    return dataframe: dataframe which contains valid stores for each retailer_item_id and group\n",
    "    \"\"\"\n",
    "    grouped_days = df.groupby(['retailer_item_id', 'organization_unit_num', 'group'], \n",
    "                                as_index=False)['sales_dt'].count()\\\n",
    "                        .rename({'sales_dt': '# days in the group'}, axis='columns')\n",
    "    grouped_stores = grouped_days.groupby(['retailer_item_id', 'group'], \n",
    "                                          as_index=False)['# days in the group'].quantile(percentile)\\\n",
    "                        .rename({'# days in the group': 'membership_threshold'}, axis='columns')\n",
    "    \n",
    "    grouped_days = grouped_days.merge(grouped_stores)\n",
    "    \n",
    "    grouped_days = grouped_days[grouped_days['# days in the group']>=grouped_days['membership_threshold']]\n",
    "    \n",
    "    return grouped_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_count_stores(df, group_columns, new_name):\n",
    "    df = df.groupby(group_columns, as_index=False)['organization_unit_num']\\\n",
    "            .count()\\\n",
    "            .rename({'organization_unit_num': new_name}, axis='columns')\n",
    "    return df\n",
    "\n",
    "\n",
    "def invalid_osa(df, valid_osa_ratio):\n",
    "    \"\"\" For a given date returns a table of all invalid OSA alerts\n",
    "    \n",
    "    param dataframe df: Input dataframe of one group and date\n",
    "    param valid_osa_ratio: threshold ratio of number of LSV/total to reject osa alerts\n",
    "    \n",
    "    \"\"\"\n",
    "    df_num_total_stores = grouped_count_stores(df, ['retailer_item_id', 'retailer_item_desc', '0.1_daily_num_stores'], 'num_total_stores')\n",
    "    df_num_lsv_stores = grouped_count_stores(df[df['lost_sales_amt']>0], ['retailer_item_id', 'retailer_item_desc', '0.1_daily_num_stores'], 'num_lsv_stores')\n",
    "    \n",
    "    df_num_lsv_stores = df_num_lsv_stores.merge(df_num_total_stores)\n",
    "    df_num_lsv_stores.loc[:, 'ratio'] = df_num_lsv_stores['num_lsv_stores']/df_num_lsv_stores['num_total_stores']\n",
    "    return df_num_lsv_stores[(df_num_lsv_stores['ratio']>=valid_osa_ratio) & (df_num_lsv_stores['num_total_stores']>=df_num_lsv_stores['0.1_daily_num_stores'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_clustering(df, col_name, percentile_high, percentile_low, minimum_pos, membership_percentile, minimum_day_ratio, start_date, end_date):\n",
    "    \n",
    "    selected_cols = ['sales_dt', 'organization_unit_num', 'retailer_item_id', 'pos_item_qty', 'price']\n",
    "    \n",
    "    df_inp = df[selected_cols][(df['sales_dt']>=start_date) & (df['sales_dt']<end_date)]\n",
    "\n",
    "    df_grouped = df_inp.groupby(['retailer_item_id']).apply(add_daily_group, \n",
    "                                                            col_name=col_name, \n",
    "                                                            percentile_high=percentile_high, \n",
    "                                                            percentile_low=percentile_low, \n",
    "                                                            minimum_pos=minimum_pos)\n",
    "\n",
    "    # drop all days in group 'slow'\n",
    "    df_grouped = df_grouped[df_grouped['group']!='slow']\n",
    "\n",
    "    membership_threshold_df = select_percentile_comb(df_grouped, membership_percentile)\n",
    "\n",
    "    # Decide to accept threshold\n",
    "    minimum_days = (dtm.datetime.strptime(end_date, '%Y-%m-%d') - dtm.datetime.strptime(start_date, '%Y-%m-%d')).days\n",
    "    membership_threshold_df = membership_threshold_df[membership_threshold_df['membership_threshold']>=minimum_day_ratio*minimum_days]\n",
    "\n",
    "    df_out = df_inp.merge(membership_threshold_df)\n",
    "\n",
    "    assigned_grouped = df_out.groupby(['organization_unit_num', \n",
    "                                       'retailer_item_id', 'group'], \n",
    "                                      as_index=False)['organization_unit_num', 'retailer_item_id', 'group'].apply(lambda x: x.drop_duplicates())\n",
    "    return assigned_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retailer = 'tesco'\n",
    "client = 'kraftheinz'\n",
    "df = load_pos_data(f'./data/{client}_{retailer}_Oct2019_March2020_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "col_name = 'pos_item_qty'\n",
    "percentile_high = 0.8\n",
    "percentile_low = 0.6\n",
    "minimum_pos = 2\n",
    "percentile = 0.8\n",
    "membership_percentile = 0.8\n",
    "valid_osa_ratio = 0.6\n",
    "minimum_day_ratio = 0.05\n",
    "MIN_TOTAL_STORE_PERCENT = 0.1\n",
    "\n",
    "# Add total number of stores for item day and calculate 10% of that number\n",
    "df_total_stores = grouped_count_stores(df, ['retailer_item_id', 'sales_dt'], 'daily_num_stores')\n",
    "df = df.merge(df_total_stores)\n",
    "df.loc[:, '0.1_daily_num_stores'] = df['daily_num_stores'] * MIN_TOTAL_STORE_PERCENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do store grouping\n",
    "start_date = '2019-10-01'\n",
    "end_date = '2020-01-01'\n",
    "df_grouped = store_clustering(df, col_name, \n",
    "                              percentile_high, \n",
    "                              percentile_low, \n",
    "                              minimum_pos, \n",
    "                              membership_percentile, \n",
    "                              minimum_day_ratio, \n",
    "                              start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_groups = df.merge(df_grouped)\n",
    "\n",
    "#Invalid OSA\n",
    "df_invalid_osa = df_with_groups.groupby(['sales_dt']).apply(invalid_osa, \n",
    "                                                            valid_osa_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stephen DS Python 3.7 (dspy37)",
   "language": "python",
   "name": "dspy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
